{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-Gram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232310"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('wizard_of_oz.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DOROTHY AND THE WIZARD IN OZ\n",
      "\n",
      "  BY\n",
      "\n",
      "  L. FRANK BAUM\n",
      "\n",
      "  AUTHOR OF THE WIZARD OF OZ, THE LAND OF OZ, OZMA OF OZ, ETC.\n",
      "\n",
      "  ILLUSTRATED BY JOHN R. NEILL\n",
      "\n",
      "  BOOKS OF WONDER WILLIAM MORROW & CO., INC. NEW\n"
     ]
    }
   ],
   "source": [
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['\\n',\n",
       "  ' ',\n",
       "  '!',\n",
       "  '\"',\n",
       "  '&',\n",
       "  \"'\",\n",
       "  '(',\n",
       "  ')',\n",
       "  '*',\n",
       "  ',',\n",
       "  '-',\n",
       "  '.',\n",
       "  '0',\n",
       "  '1',\n",
       "  '2',\n",
       "  '3',\n",
       "  '4',\n",
       "  '5',\n",
       "  '6',\n",
       "  '7',\n",
       "  '8',\n",
       "  '9',\n",
       "  ':',\n",
       "  ';',\n",
       "  '?',\n",
       "  'A',\n",
       "  'B',\n",
       "  'C',\n",
       "  'D',\n",
       "  'E',\n",
       "  'F',\n",
       "  'G',\n",
       "  'H',\n",
       "  'I',\n",
       "  'J',\n",
       "  'K',\n",
       "  'L',\n",
       "  'M',\n",
       "  'N',\n",
       "  'O',\n",
       "  'P',\n",
       "  'Q',\n",
       "  'R',\n",
       "  'S',\n",
       "  'T',\n",
       "  'U',\n",
       "  'V',\n",
       "  'W',\n",
       "  'X',\n",
       "  'Y',\n",
       "  'Z',\n",
       "  '[',\n",
       "  ']',\n",
       "  '_',\n",
       "  'a',\n",
       "  'b',\n",
       "  'c',\n",
       "  'd',\n",
       "  'e',\n",
       "  'f',\n",
       "  'g',\n",
       "  'h',\n",
       "  'i',\n",
       "  'j',\n",
       "  'k',\n",
       "  'l',\n",
       "  'm',\n",
       "  'n',\n",
       "  'o',\n",
       "  'p',\n",
       "  'q',\n",
       "  'r',\n",
       "  's',\n",
       "  't',\n",
       "  'u',\n",
       "  'v',\n",
       "  'w',\n",
       "  'x',\n",
       "  'y',\n",
       "  'z',\n",
       "  '\\ufeff'],\n",
       " 81)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(set(text))\n",
    "chars, len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int = {ch:i for i,ch in enumerate(chars)}\n",
    "int_to_string = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([61, 58, 65, 65, 68], 'hello')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_word = encode('hello')\n",
    "decoded_word = decode(encoded_word)\n",
    "\n",
    "encoded_word, decoded_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
       "         1, 47, 33, 50, 25, 42, 28,  1, 33, 38,  1, 39, 50,  0,  0,  1,  1, 26,\n",
       "        49,  0,  0,  1,  1, 36, 11,  1, 30, 42, 25, 38, 35,  1, 26, 25, 45, 37,\n",
       "         0,  0,  1,  1, 25, 45, 44, 32, 39, 42,  1, 39, 30,  1, 44, 32, 29,  1,\n",
       "        47, 33, 50, 25, 42, 28,  1, 39, 30,  1, 39, 50,  9,  1, 44, 32, 29,  1,\n",
       "        36, 25, 38, 28,  1, 39, 30,  1, 39, 50])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "data = torch.Tensor(encode(text)).type(torch.long)\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([80]), target is 1\n",
      "When input is tensor([80,  1]), target is 1\n",
      "When input is tensor([80,  1,  1]), target is 28\n",
      "When input is tensor([80,  1,  1, 28]), target is 39\n",
      "When input is tensor([80,  1,  1, 28, 39]), target is 42\n",
      "When input is tensor([80,  1,  1, 28, 39, 42]), target is 39\n",
      "When input is tensor([80,  1,  1, 28, 39, 42, 39]), target is 44\n",
      "When input is tensor([80,  1,  1, 28, 39, 42, 39, 44]), target is 32\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "\n",
    "X = train_data[:block_size]\n",
    "Y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = X[:t+1]\n",
    "    target = Y[t]\n",
    "    print(f'When input is {context}, target is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 6])\n",
      "tensor([[ 0.8591,  2.7228, -0.5484, -0.1491,  0.3851,  0.6441],\n",
      "        [ 0.2710, -1.0774,  1.4590,  0.3323, -1.6848,  0.8318],\n",
      "        [-0.8694, -0.3782, -1.2340,  0.1948,  0.5592, -0.5220],\n",
      "        [ 0.0528, -1.9901, -0.2951, -0.8300,  1.5629, -0.1984]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Initialize an embedding layer\n",
    "vocab_size = 80\n",
    "embedding_dim = 6\n",
    "embedding = nn.Embedding(vocab_size,embedding_dim)\n",
    "\n",
    "# Create some input indices\n",
    "input_indices = torch.LongTensor([1,5,3,2])\n",
    "\n",
    "# Apply the embedding layer\n",
    "embedded_output = embedding(input_indices)\n",
    "\n",
    "# The output will be a tensor of shape (4,100) where 4 is the number of inputs & 100 is the dimensionality of the embedding vectors\n",
    "print(embedded_output.shape)\n",
    "print(embedded_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "max_iters = 1000\n",
    "eval_interval = 2500\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 250\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['\\n',\n",
       "  ' ',\n",
       "  '!',\n",
       "  '\"',\n",
       "  '&',\n",
       "  \"'\",\n",
       "  '(',\n",
       "  ')',\n",
       "  '*',\n",
       "  ',',\n",
       "  '-',\n",
       "  '.',\n",
       "  '0',\n",
       "  '1',\n",
       "  '2',\n",
       "  '3',\n",
       "  '4',\n",
       "  '5',\n",
       "  '6',\n",
       "  '7',\n",
       "  '8',\n",
       "  '9',\n",
       "  ':',\n",
       "  ';',\n",
       "  '?',\n",
       "  'A',\n",
       "  'B',\n",
       "  'C',\n",
       "  'D',\n",
       "  'E',\n",
       "  'F',\n",
       "  'G',\n",
       "  'H',\n",
       "  'I',\n",
       "  'J',\n",
       "  'K',\n",
       "  'L',\n",
       "  'M',\n",
       "  'N',\n",
       "  'O',\n",
       "  'P',\n",
       "  'Q',\n",
       "  'R',\n",
       "  'S',\n",
       "  'T',\n",
       "  'U',\n",
       "  'V',\n",
       "  'W',\n",
       "  'X',\n",
       "  'Y',\n",
       "  'Z',\n",
       "  '[',\n",
       "  ']',\n",
       "  '_',\n",
       "  'a',\n",
       "  'b',\n",
       "  'c',\n",
       "  'd',\n",
       "  'e',\n",
       "  'f',\n",
       "  'g',\n",
       "  'h',\n",
       "  'i',\n",
       "  'j',\n",
       "  'k',\n",
       "  'l',\n",
       "  'm',\n",
       "  'n',\n",
       "  'o',\n",
       "  'p',\n",
       "  'q',\n",
       "  'r',\n",
       "  's',\n",
       "  't',\n",
       "  'u',\n",
       "  'v',\n",
       "  'w',\n",
       "  'x',\n",
       "  'y',\n",
       "  'z',\n",
       "  '\\ufeff'],\n",
       " 81)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('wizard_of_oz.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "# len(text)\n",
    "chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "chars, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([80,  1,  1, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,\n",
       "         1, 47, 33, 50, 25, 42, 28,  1, 33, 38,  1, 39, 50,  0,  0,  1,  1, 26,\n",
       "        49,  0,  0,  1,  1, 36, 11,  1, 30, 42, 25, 38, 35,  1, 26, 25, 45, 37,\n",
       "         0,  0,  1,  1, 25, 45, 44, 32, 39, 42,  1, 39, 30,  1, 44, 32, 29,  1,\n",
       "        47, 33, 50, 25, 42, 28,  1, 39, 30,  1, 39, 50,  9,  1, 44, 32, 29,  1,\n",
       "        36, 25, 38, 28,  1, 39, 30,  1, 39, 50])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_to_int = {ch:i for i,ch in enumerate(chars)}\n",
    "int_to_string = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "data = torch.Tensor(encode(text)).type(torch.long)\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([80]), target is 1\n",
      "When input is tensor([80,  1]), target is 1\n",
      "When input is tensor([80,  1,  1]), target is 28\n",
      "When input is tensor([80,  1,  1, 28]), target is 39\n",
      "When input is tensor([80,  1,  1, 28, 39]), target is 42\n",
      "When input is tensor([80,  1,  1, 28, 39, 42]), target is 39\n",
      "When input is tensor([80,  1,  1, 28, 39, 42, 39]), target is 44\n",
      "When input is tensor([80,  1,  1, 28, 39, 42, 39, 44]), target is 32\n"
     ]
    }
   ],
   "source": [
    "X = train_data[:block_size]\n",
    "Y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = X[:t+1]\n",
    "    target = Y[t]\n",
    "    print(f'When input is {context}, target is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[ 3,  0,  0, 43, 68,  1, 73, 68],\n",
      "        [67, 57,  0, 73, 76, 62, 72, 73],\n",
      "        [68, 74, 67, 57,  1, 73, 61, 58],\n",
      "        [72,  1, 72, 61, 58,  1, 69, 58]])\n",
      "targets:\n",
      "tensor([[ 0,  0, 43, 68,  1, 73, 68, 60],\n",
      "        [57,  0, 73, 76, 62, 72, 73, 62],\n",
      "        [74, 67, 57,  1, 73, 61, 58, 66],\n",
      "        [ 1, 72, 61, 58,  1, 69, 58, 58]])\n"
     ]
    }
   ],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else test_data\n",
    "    ix = torch.randint(len(data) - block_size,(batch_size,))\n",
    "    #print(ix)\n",
    "    X = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    Y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    X, Y = X.to(device), Y.to(device)\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "X, Y = get_batch('train')\n",
    "print(f'inputs:\\n{X}\\ntargets:\\n{Y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1K4z:vd)xAex*fRkUB  V)NzeY&hw*jJLXV&6hp)!2'\n",
      "5h\"i5VWNi)U5tMm '-M;y2L4d2'\n",
      "[ME*eTxM5&H67T9z4DW\n",
      "G]q['NEz&TiC1 CMRkz'-\"rAampk,K\"G(4Qxswrz]ab(,f.Zj0cq6B5k,xYGzvsPir*BgPvHXvo_8I-BUY&]mEkX4Q5'kp1ImNxADWa\n",
      "FzpSqr*!)x,p]!!]p)x5pd(zR oWrdvTRk1uTEQUm;6vH_&*89&[y*6djJh74Mf&6FZnMobIBzTe[a'kcRFzdu3DgoD?'- !6Fh;iEUYAcE4E7A0'TEXq,KuUocT,-z!:]7a\n",
      "zl.LA'-*E*p'4(ZWsc89*c4s2.10a\",11I,[m\"E'sU\n",
      " w,XKhpBoMG3Cer5kp]O(3!B]\"xTE'xJiA TIng,p55c]Q23I-MDgm*d2.Ez7.0!Xz7_dVa2nQcVy'k2pg*lrUO1NercFKn!A\"r7a[aj6MfcT(,:]d&\"UV0\"Bk,3'l;0\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        logits = self.token_embedding_table(index)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = nn.functional.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self.forward(index)\n",
    "\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "\n",
    "            # apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1) # (B, C)\n",
    "\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
    "\n",
    "        return index\n",
    "    \n",
    "model = BigramLanguageModel(vocab_size).to(device)\n",
    "\n",
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(model.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_loss(model):\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        out = {}\n",
    "        for split in ['train', 'val']:\n",
    "            losses = torch.zeros(eval_iters)\n",
    "            for k in range(eval_iters):\n",
    "                X, Y = get_batch(split)\n",
    "                logits, loss = model(X, Y)\n",
    "                losses[k] = loss.item()\n",
    "            out[split] = losses.mean()\n",
    "    model.train()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0,\ttrain loss: 2.583,\tval loss: 2.582\n",
      "step: 250,\ttrain loss: 2.538,\tval loss: 2.561\n",
      "step: 500,\ttrain loss: 2.548,\tval loss: 2.568\n",
      "step: 750,\ttrain loss: 2.532,\tval loss: 2.555\n",
      "2.198699474334717\n"
     ]
    }
   ],
   "source": [
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss(model)\n",
    "        print(f\"step: {iter},\\ttrain loss: {losses['train']:.3f},\\tval loss: {losses['val']:.3f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Han\n",
      "\n",
      "IUWhe.\"Thtl, aperedig are imloc&4g o tra re tulley watutaliced pssere sue, med f':ealmpsp sigans he the f by sed gheth peverin T-O11.\"\n",
      "D e Them dd ilL8INz_le. ure unghebud lle be aleot, ISllone ck s 1;?\"F(B,\"OYKZerervamengragy lly,x\"Hkld TEullirthid id bYU?PQX:xl s heyoy.\"7jQ\n",
      "\n",
      "\"D\"Dowererompswad;0edeyoye opo\n",
      "\n",
      "id EX*7Mand by,\n",
      "hes, tepr t m1Wl. mag s ak'Ssthee d anothigP:_ TVime, My an INQonerllo t s, BV?\"Wicapotout wit UjG!5q6R.\n",
      "\n",
      " ullorm le ke cr kee aliong;y th whed dRf ig c4&F&k\n",
      "\n",
      "\"\n",
      "fra m S'\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(model.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
