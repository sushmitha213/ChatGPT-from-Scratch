{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "s78F77JKpSzy",
        "outputId": "2549c8b8-7368-412b-d6ec-c46067bca028"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import mmap\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "batch_size = 32\n",
        "block_size = 128\n",
        "max_iters = 3000\n",
        "learning_rate = 3e-4\n",
        "eval_iters = 100\n",
        "n_embd = 384\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.2\n",
        "\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY0UBjGepSz0",
        "outputId": "fd3c5cdc-ff10-4410-f971-4c57adc095c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['\\x00',\n",
              "  '\\n',\n",
              "  ' ',\n",
              "  '!',\n",
              "  '\"',\n",
              "  '#',\n",
              "  '$',\n",
              "  '%',\n",
              "  '&',\n",
              "  \"'\",\n",
              "  '(',\n",
              "  ')',\n",
              "  '*',\n",
              "  '+',\n",
              "  ',',\n",
              "  '-',\n",
              "  '.',\n",
              "  '/',\n",
              "  '0',\n",
              "  '1',\n",
              "  '2',\n",
              "  '3',\n",
              "  '4',\n",
              "  '5',\n",
              "  '6',\n",
              "  '7',\n",
              "  '8',\n",
              "  '9',\n",
              "  ':',\n",
              "  ';',\n",
              "  '<',\n",
              "  '=',\n",
              "  '>',\n",
              "  '?',\n",
              "  '@',\n",
              "  'A',\n",
              "  'B',\n",
              "  'C',\n",
              "  'D',\n",
              "  'E',\n",
              "  'F',\n",
              "  'G',\n",
              "  'H',\n",
              "  'I',\n",
              "  'J',\n",
              "  'K',\n",
              "  'L',\n",
              "  'M',\n",
              "  'N',\n",
              "  'O',\n",
              "  'P',\n",
              "  'Q',\n",
              "  'R',\n",
              "  'S',\n",
              "  'T',\n",
              "  'U',\n",
              "  'V',\n",
              "  'W',\n",
              "  'X',\n",
              "  'Y',\n",
              "  'Z',\n",
              "  '[',\n",
              "  '\\\\',\n",
              "  ']',\n",
              "  '^',\n",
              "  '_',\n",
              "  '`',\n",
              "  'a',\n",
              "  'b',\n",
              "  'c',\n",
              "  'd',\n",
              "  'e',\n",
              "  'f',\n",
              "  'g',\n",
              "  'h',\n",
              "  'i',\n",
              "  'j',\n",
              "  'k',\n",
              "  'l',\n",
              "  'm',\n",
              "  'n',\n",
              "  'o',\n",
              "  'p',\n",
              "  'q',\n",
              "  'r',\n",
              "  's',\n",
              "  't',\n",
              "  'u',\n",
              "  'v',\n",
              "  'w',\n",
              "  'x',\n",
              "  'y',\n",
              "  'z',\n",
              "  '{',\n",
              "  '|',\n",
              "  '}',\n",
              "  '~',\n",
              "  '\\x7f',\n",
              "  '\\x80',\n",
              "  '\\x81',\n",
              "  '\\x82',\n",
              "  '\\x83',\n",
              "  '\\x84',\n",
              "  '\\x86',\n",
              "  '\\x87',\n",
              "  '\\x88',\n",
              "  '\\x89',\n",
              "  '\\x8a',\n",
              "  '\\x8b',\n",
              "  '\\x8c',\n",
              "  '\\x8d',\n",
              "  '\\x8e',\n",
              "  '\\x8f',\n",
              "  '\\x90',\n",
              "  '\\x91',\n",
              "  '\\x92',\n",
              "  '\\x93',\n",
              "  '\\x94',\n",
              "  '\\x95',\n",
              "  '\\x96',\n",
              "  '\\x97',\n",
              "  '\\x98',\n",
              "  '\\x99',\n",
              "  '\\x9a',\n",
              "  '\\x9b',\n",
              "  '\\x9c',\n",
              "  '\\x9d',\n",
              "  '\\x9e',\n",
              "  '\\x9f',\n",
              "  '¡',\n",
              "  '¢',\n",
              "  '£',\n",
              "  '¤',\n",
              "  '¥',\n",
              "  '¦',\n",
              "  '§',\n",
              "  '¨',\n",
              "  '©',\n",
              "  'ª',\n",
              "  '«',\n",
              "  '¬',\n",
              "  '\\xad',\n",
              "  '®',\n",
              "  '¯',\n",
              "  '°',\n",
              "  '±',\n",
              "  '²',\n",
              "  '³',\n",
              "  '´',\n",
              "  'µ',\n",
              "  '¶',\n",
              "  '·',\n",
              "  '¸',\n",
              "  '¹',\n",
              "  'º',\n",
              "  '»',\n",
              "  '¼',\n",
              "  '½',\n",
              "  '¾',\n",
              "  '¿',\n",
              "  'À',\n",
              "  'Á',\n",
              "  'Â',\n",
              "  'Ã',\n",
              "  'Ä',\n",
              "  'Å',\n",
              "  'Æ',\n",
              "  'Ç',\n",
              "  'È',\n",
              "  'É',\n",
              "  'Ê',\n",
              "  'Ë',\n",
              "  'Ì',\n",
              "  'Í',\n",
              "  'Î',\n",
              "  'Ï',\n",
              "  'Ð',\n",
              "  'Ñ',\n",
              "  'Ò',\n",
              "  'Ó',\n",
              "  'Ô',\n",
              "  'Õ',\n",
              "  'Ö',\n",
              "  '×',\n",
              "  'Ø',\n",
              "  'Ù',\n",
              "  'Ú',\n",
              "  'Û',\n",
              "  'Ü',\n",
              "  'Ý',\n",
              "  'Þ',\n",
              "  'ß',\n",
              "  'à',\n",
              "  'á',\n",
              "  'â',\n",
              "  'ã',\n",
              "  'ä',\n",
              "  'å',\n",
              "  'æ',\n",
              "  'ç',\n",
              "  'è',\n",
              "  'é',\n",
              "  'ê',\n",
              "  'ë',\n",
              "  'ì',\n",
              "  'í',\n",
              "  'î',\n",
              "  'ï',\n",
              "  'ð',\n",
              "  'ñ',\n",
              "  'ò',\n",
              "  'ó',\n",
              "  'ô',\n",
              "  'õ',\n",
              "  'ö',\n",
              "  '÷',\n",
              "  'ø',\n",
              "  'ù',\n",
              "  'ú',\n",
              "  'û',\n",
              "  'ü',\n",
              "  'ý',\n",
              "  'þ',\n",
              "  'ÿ',\n",
              "  'Ā',\n",
              "  'ā',\n",
              "  'Ă',\n",
              "  'ă',\n",
              "  'Ą',\n",
              "  'ą',\n",
              "  'Ć',\n",
              "  'ć',\n",
              "  'Ĉ',\n",
              "  'ĉ',\n",
              "  'Ċ',\n",
              "  'ċ',\n",
              "  'Č',\n",
              "  'č',\n",
              "  'Ď',\n",
              "  'ď',\n",
              "  'Đ',\n",
              "  'đ',\n",
              "  'Ē',\n",
              "  'ē',\n",
              "  'Ĕ',\n",
              "  'ĕ',\n",
              "  'Ė',\n",
              "  'ė',\n",
              "  'Ę',\n",
              "  'ę',\n",
              "  'Ě',\n",
              "  'ě',\n",
              "  'Ĝ',\n",
              "  'ĝ',\n",
              "  'Ğ',\n",
              "  'ğ',\n",
              "  'Ġ',\n",
              "  'ġ',\n",
              "  'Ģ',\n",
              "  'ģ',\n",
              "  'Ĥ',\n",
              "  'ĥ',\n",
              "  'Ħ',\n",
              "  'ħ',\n",
              "  'Ĩ',\n",
              "  'ĩ',\n",
              "  'Ī',\n",
              "  'ī',\n",
              "  'Ĭ',\n",
              "  'ĭ',\n",
              "  'Į',\n",
              "  'į',\n",
              "  'İ',\n",
              "  'ı',\n",
              "  'Ĳ',\n",
              "  'ĳ',\n",
              "  'Ĵ',\n",
              "  'ĵ',\n",
              "  'Ķ',\n",
              "  'ķ',\n",
              "  'ĸ',\n",
              "  'Ĺ',\n",
              "  'ĺ',\n",
              "  'Ļ',\n",
              "  'ļ',\n",
              "  'Ľ',\n",
              "  'ľ',\n",
              "  'Ŀ',\n",
              "  'ŀ',\n",
              "  'Ł',\n",
              "  'ł',\n",
              "  'Ń',\n",
              "  'ń',\n",
              "  'Ņ',\n",
              "  'ņ',\n",
              "  'Ň',\n",
              "  'ň',\n",
              "  'ŉ',\n",
              "  'Ŋ',\n",
              "  'ŋ',\n",
              "  'Ō',\n",
              "  'ō',\n",
              "  'Ŏ',\n",
              "  'ŏ',\n",
              "  'Ő',\n",
              "  'ő',\n",
              "  'Œ',\n",
              "  'œ',\n",
              "  'Ŕ',\n",
              "  'ŕ',\n",
              "  'Ŗ',\n",
              "  'ŗ',\n",
              "  'Ř',\n",
              "  'ř',\n",
              "  'Ś',\n",
              "  'ś',\n",
              "  'Ŝ',\n",
              "  'ŝ',\n",
              "  'Ş',\n",
              "  'ş',\n",
              "  'Š',\n",
              "  'š',\n",
              "  'Ţ',\n",
              "  'ţ',\n",
              "  'Ť',\n",
              "  'ť',\n",
              "  'Ŧ',\n",
              "  'ŧ',\n",
              "  'Ũ',\n",
              "  'ũ',\n",
              "  'Ū',\n",
              "  'ū',\n",
              "  'Ŭ',\n",
              "  'ŭ',\n",
              "  'Ů',\n",
              "  'ů',\n",
              "  'Ű',\n",
              "  'ű',\n",
              "  'Ų',\n",
              "  'ų',\n",
              "  'Ŵ',\n",
              "  'ŵ',\n",
              "  'Ŷ',\n",
              "  'ŷ',\n",
              "  'Ÿ',\n",
              "  'Ź',\n",
              "  'ź',\n",
              "  'Ż',\n",
              "  'ż',\n",
              "  'Ž',\n",
              "  'ž',\n",
              "  'ſ',\n",
              "  'ƀ',\n",
              "  'Ɓ',\n",
              "  'Ƃ',\n",
              "  'ƃ',\n",
              "  'Ƅ',\n",
              "  'ƅ',\n",
              "  'Ɔ',\n",
              "  'Ƈ',\n",
              "  'ƈ',\n",
              "  'Ɖ',\n",
              "  'Ɗ',\n",
              "  'Ƌ',\n",
              "  'ƌ',\n",
              "  'ƍ',\n",
              "  'Ǝ',\n",
              "  'Ə',\n",
              "  'Ɛ',\n",
              "  'Ƒ',\n",
              "  'ƒ',\n",
              "  'Ɠ',\n",
              "  'Ɣ',\n",
              "  'ƕ',\n",
              "  'Ɩ',\n",
              "  'Ɨ',\n",
              "  'Ƙ',\n",
              "  'ƙ',\n",
              "  'ƚ',\n",
              "  'ƛ',\n",
              "  'Ɯ',\n",
              "  'Ɲ',\n",
              "  'ƞ',\n",
              "  'Ɵ',\n",
              "  'Ơ',\n",
              "  'ơ',\n",
              "  'Ƣ',\n",
              "  'ƣ',\n",
              "  'Ƥ',\n",
              "  'ƥ',\n",
              "  'Ʀ',\n",
              "  'Ƨ',\n",
              "  'ƨ',\n",
              "  'Ʃ',\n",
              "  'ƪ',\n",
              "  'ƫ',\n",
              "  'Ƭ',\n",
              "  'ƭ',\n",
              "  'Ʈ',\n",
              "  'Ư',\n",
              "  'ư',\n",
              "  'Ʊ',\n",
              "  'Ʋ',\n",
              "  'Ƴ',\n",
              "  'ƴ',\n",
              "  'Ƶ',\n",
              "  'ƶ',\n",
              "  'Ʒ',\n",
              "  'Ƹ',\n",
              "  'ƹ',\n",
              "  'ƺ',\n",
              "  'ƻ',\n",
              "  'Ƽ',\n",
              "  'ƽ',\n",
              "  'ƾ',\n",
              "  'ƿ',\n",
              "  'ǀ',\n",
              "  'ǁ',\n",
              "  'ǂ',\n",
              "  'ǃ',\n",
              "  'Ǆ',\n",
              "  'ǅ',\n",
              "  'ǆ',\n",
              "  'Ǉ',\n",
              "  'ǈ',\n",
              "  'ǉ',\n",
              "  'Ǌ',\n",
              "  'ǋ',\n",
              "  'ǌ',\n",
              "  'Ǎ',\n",
              "  'ǎ',\n",
              "  'Ǐ',\n",
              "  'ǐ',\n",
              "  'Ǒ',\n",
              "  'ǒ',\n",
              "  'Ǔ',\n",
              "  'ǔ',\n",
              "  'Ǖ',\n",
              "  'ǖ',\n",
              "  'Ǘ',\n",
              "  'ǘ',\n",
              "  'Ǚ',\n",
              "  'ǚ',\n",
              "  'Ǜ',\n",
              "  'ǜ',\n",
              "  'ǝ',\n",
              "  'Ǟ',\n",
              "  'ǟ',\n",
              "  'Ǡ',\n",
              "  'ǡ',\n",
              "  'Ǣ',\n",
              "  'ǣ',\n",
              "  'Ǥ',\n",
              "  'ǥ',\n",
              "  'Ǧ',\n",
              "  'ǧ',\n",
              "  'Ǩ',\n",
              "  'ǩ',\n",
              "  'Ǫ',\n",
              "  'ǫ',\n",
              "  'Ǭ',\n",
              "  'ǭ',\n",
              "  'Ǯ',\n",
              "  'ǯ',\n",
              "  'ǰ',\n",
              "  'Ǳ',\n",
              "  'ǲ',\n",
              "  'ǳ',\n",
              "  'Ǵ',\n",
              "  'ǵ',\n",
              "  'Ƕ',\n",
              "  'Ƿ',\n",
              "  'Ǹ',\n",
              "  'ǹ',\n",
              "  'Ǻ',\n",
              "  'ǻ',\n",
              "  'Ǽ',\n",
              "  'ǽ',\n",
              "  'Ǿ',\n",
              "  'ǿ',\n",
              "  'Ȁ',\n",
              "  'ȁ',\n",
              "  'Ȃ',\n",
              "  'ȃ',\n",
              "  'Ȅ',\n",
              "  'ȅ',\n",
              "  'Ȇ',\n",
              "  'ȇ',\n",
              "  'Ȉ',\n",
              "  'ȉ',\n",
              "  'Ȋ',\n",
              "  'ȋ',\n",
              "  'Ȍ',\n",
              "  'ȍ',\n",
              "  'Ȏ',\n",
              "  'ȏ',\n",
              "  'Ȑ',\n",
              "  'ȑ',\n",
              "  'Ȓ',\n",
              "  'ȓ',\n",
              "  'Ȕ',\n",
              "  'ȕ',\n",
              "  'Ȗ',\n",
              "  'ȗ',\n",
              "  'Ș',\n",
              "  'ș',\n",
              "  'Ț',\n",
              "  'ț',\n",
              "  'Ȝ',\n",
              "  'ȝ',\n",
              "  'Ȟ',\n",
              "  'ȟ',\n",
              "  'Ƞ',\n",
              "  'ȡ',\n",
              "  'Ȣ',\n",
              "  'ȣ',\n",
              "  'Ȥ',\n",
              "  'ȥ',\n",
              "  'Ȧ',\n",
              "  'ȧ',\n",
              "  'Ȩ',\n",
              "  'ȩ',\n",
              "  'Ȫ',\n",
              "  'ȫ',\n",
              "  'Ȭ',\n",
              "  'ȭ',\n",
              "  'Ȯ',\n",
              "  'ȯ',\n",
              "  'Ȱ',\n",
              "  'ȱ',\n",
              "  'Ȳ',\n",
              "  'ȳ',\n",
              "  'ȴ',\n",
              "  'ȵ',\n",
              "  'ȶ',\n",
              "  'ȷ',\n",
              "  'ȸ',\n",
              "  'ȹ',\n",
              "  'Ⱥ',\n",
              "  'Ȼ',\n",
              "  'ȼ',\n",
              "  'Ƚ',\n",
              "  'Ⱦ',\n",
              "  'ȿ',\n",
              "  'ɀ',\n",
              "  'Ɂ',\n",
              "  'ɂ',\n",
              "  'Ƀ',\n",
              "  'Ʉ',\n",
              "  'Ʌ',\n",
              "  'Ɇ',\n",
              "  'ɇ',\n",
              "  'Ɉ',\n",
              "  'ɉ',\n",
              "  'Ɋ',\n",
              "  'ɋ',\n",
              "  'Ɍ',\n",
              "  'ɍ',\n",
              "  'Ɏ',\n",
              "  'ɏ',\n",
              "  'ɐ',\n",
              "  'ɑ',\n",
              "  'ɒ',\n",
              "  'ɓ',\n",
              "  'ɔ',\n",
              "  'ɕ',\n",
              "  'ɖ',\n",
              "  'ɗ',\n",
              "  'ɘ',\n",
              "  'ə',\n",
              "  'ɚ',\n",
              "  'ɛ',\n",
              "  'ɜ',\n",
              "  'ɝ',\n",
              "  'ɞ',\n",
              "  'ɟ',\n",
              "  'ɠ',\n",
              "  'ɡ',\n",
              "  'ɢ',\n",
              "  'ɣ',\n",
              "  'ɤ',\n",
              "  'ɥ',\n",
              "  'ɦ',\n",
              "  'ɧ',\n",
              "  'ɨ',\n",
              "  'ɩ',\n",
              "  'ɪ',\n",
              "  'ɫ',\n",
              "  'ɬ',\n",
              "  'ɭ',\n",
              "  'ɮ',\n",
              "  'ɯ',\n",
              "  'ɰ',\n",
              "  'ɱ',\n",
              "  'ɲ',\n",
              "  'ɳ',\n",
              "  'ɴ',\n",
              "  'ɵ',\n",
              "  'ɶ',\n",
              "  'ɷ',\n",
              "  'ɸ',\n",
              "  'ɹ',\n",
              "  'ɺ',\n",
              "  'ɻ',\n",
              "  'ɼ',\n",
              "  'ɽ',\n",
              "  'ɾ',\n",
              "  'ɿ',\n",
              "  'ʀ',\n",
              "  'ʁ',\n",
              "  'ʂ',\n",
              "  'ʃ',\n",
              "  'ʄ',\n",
              "  'ʅ',\n",
              "  'ʆ',\n",
              "  'ʇ',\n",
              "  'ʈ',\n",
              "  'ʉ',\n",
              "  'ʊ',\n",
              "  'ʋ',\n",
              "  'ʌ',\n",
              "  'ʍ',\n",
              "  'ʎ',\n",
              "  'ʏ',\n",
              "  'ʐ',\n",
              "  'ʑ',\n",
              "  'ʒ',\n",
              "  'ʓ',\n",
              "  'ʔ',\n",
              "  'ʕ',\n",
              "  'ʖ',\n",
              "  'ʗ',\n",
              "  'ʘ',\n",
              "  'ʙ',\n",
              "  'ʚ',\n",
              "  'ʛ',\n",
              "  'ʜ',\n",
              "  'ʝ',\n",
              "  'ʞ',\n",
              "  'ʟ',\n",
              "  'ʠ',\n",
              "  'ʡ',\n",
              "  'ʢ',\n",
              "  'ʣ',\n",
              "  'ʤ',\n",
              "  'ʥ',\n",
              "  'ʦ',\n",
              "  'ʧ',\n",
              "  'ʨ',\n",
              "  'ʩ',\n",
              "  'ʪ',\n",
              "  'ʫ',\n",
              "  'ʬ',\n",
              "  'ʭ',\n",
              "  'ʯ',\n",
              "  'ʰ',\n",
              "  'ʱ',\n",
              "  'ʲ',\n",
              "  'ʳ',\n",
              "  'ʴ',\n",
              "  'ʵ',\n",
              "  'ʶ',\n",
              "  'ʷ',\n",
              "  'ʸ',\n",
              "  'ʹ',\n",
              "  'ʺ',\n",
              "  'ʻ',\n",
              "  'ʼ',\n",
              "  'ʽ',\n",
              "  'ʾ',\n",
              "  'ʿ',\n",
              "  'ˀ',\n",
              "  'ˁ',\n",
              "  '˂',\n",
              "  '˃',\n",
              "  '˄',\n",
              "  '˅',\n",
              "  'ˆ',\n",
              "  'ˇ',\n",
              "  'ˈ',\n",
              "  'ˉ',\n",
              "  'ˊ',\n",
              "  'ˋ',\n",
              "  'ˌ',\n",
              "  'ˍ',\n",
              "  'ˎ',\n",
              "  'ˏ',\n",
              "  'ː',\n",
              "  'ˑ',\n",
              "  '˒',\n",
              "  '˓',\n",
              "  '˔',\n",
              "  '˕',\n",
              "  '˖',\n",
              "  '˗',\n",
              "  '˘',\n",
              "  '˙',\n",
              "  '˚',\n",
              "  '˛',\n",
              "  '˜',\n",
              "  '˝',\n",
              "  '˞',\n",
              "  '˟',\n",
              "  'ˠ',\n",
              "  'ˡ',\n",
              "  'ˢ',\n",
              "  'ˣ',\n",
              "  'ˤ',\n",
              "  '˥',\n",
              "  '˦',\n",
              "  '˧',\n",
              "  '˨',\n",
              "  '˩',\n",
              "  '˪',\n",
              "  '˫',\n",
              "  'ˬ',\n",
              "  '˭',\n",
              "  'ˮ',\n",
              "  '˰',\n",
              "  '˱',\n",
              "  '˲',\n",
              "  '˳',\n",
              "  '˴',\n",
              "  '˵',\n",
              "  '˶',\n",
              "  '˸',\n",
              "  '˹',\n",
              "  '˺',\n",
              "  '˻',\n",
              "  '˾',\n",
              "  '̀',\n",
              "  '́',\n",
              "  '̂',\n",
              "  '̃',\n",
              "  '̄',\n",
              "  '̅',\n",
              "  '̆',\n",
              "  '̇',\n",
              "  '̈',\n",
              "  '̉',\n",
              "  '̊',\n",
              "  '̋',\n",
              "  '̌',\n",
              "  '̍',\n",
              "  '̎',\n",
              "  '̏',\n",
              "  '̐',\n",
              "  '̑',\n",
              "  '̒',\n",
              "  '̓',\n",
              "  '̔',\n",
              "  '̕',\n",
              "  '̖',\n",
              "  '̗',\n",
              "  '̘',\n",
              "  '̙',\n",
              "  '̚',\n",
              "  '̛',\n",
              "  '̜',\n",
              "  '̝',\n",
              "  '̞',\n",
              "  '̟',\n",
              "  '̠',\n",
              "  '̡',\n",
              "  '̢',\n",
              "  '̣',\n",
              "  '̤',\n",
              "  '̥',\n",
              "  '̦',\n",
              "  '̧',\n",
              "  '̨',\n",
              "  '̩',\n",
              "  '̪',\n",
              "  '̫',\n",
              "  '̬',\n",
              "  '̭',\n",
              "  '̮',\n",
              "  '̯',\n",
              "  '̰',\n",
              "  '̱',\n",
              "  '̲',\n",
              "  '̳',\n",
              "  '̴',\n",
              "  '̵',\n",
              "  '̶',\n",
              "  '̷',\n",
              "  '̸',\n",
              "  '̹',\n",
              "  '̺',\n",
              "  '̻',\n",
              "  '̼',\n",
              "  '̽',\n",
              "  '̾',\n",
              "  '̿',\n",
              "  '̀',\n",
              "  '́',\n",
              "  '͂',\n",
              "  '̓',\n",
              "  '̈́',\n",
              "  'ͅ',\n",
              "  '͆',\n",
              "  '͇',\n",
              "  '͈',\n",
              "  '͉',\n",
              "  '͊',\n",
              "  '͋',\n",
              "  '͌',\n",
              "  '͍',\n",
              "  '͎',\n",
              "  '͏',\n",
              "  '͐',\n",
              "  '͑',\n",
              "  '͒',\n",
              "  '͓',\n",
              "  '͔',\n",
              "  '͕',\n",
              "  '͖',\n",
              "  '͗',\n",
              "  '͘',\n",
              "  '͙',\n",
              "  '͚',\n",
              "  '͛',\n",
              "  '͜',\n",
              "  '͝',\n",
              "  '͞',\n",
              "  '͟',\n",
              "  '͠',\n",
              "  '͡',\n",
              "  '͢',\n",
              "  'ͣ',\n",
              "  'ͤ',\n",
              "  'ͥ',\n",
              "  'ͦ',\n",
              "  'ͧ',\n",
              "  'ͨ',\n",
              "  'ͩ',\n",
              "  'ͪ',\n",
              "  'ͫ',\n",
              "  'ͬ',\n",
              "  'ͭ',\n",
              "  'ͮ',\n",
              "  'ͯ',\n",
              "  'Ͱ',\n",
              "  'ͱ',\n",
              "  'Ͳ',\n",
              "  'ͳ',\n",
              "  'ʹ',\n",
              "  '͵',\n",
              "  'Ͷ',\n",
              "  'ͷ',\n",
              "  '\\u0378',\n",
              "  '\\u0379',\n",
              "  'ͺ',\n",
              "  'ͻ',\n",
              "  'ͼ',\n",
              "  'ͽ',\n",
              "  ';',\n",
              "  'Ϳ',\n",
              "  '\\u0380',\n",
              "  '\\u0381',\n",
              "  '\\u0382',\n",
              "  '\\u0383',\n",
              "  '΄',\n",
              "  '΅',\n",
              "  'Ά',\n",
              "  '·',\n",
              "  'Έ',\n",
              "  'Ή',\n",
              "  'Ί',\n",
              "  '\\u038b',\n",
              "  'Ό',\n",
              "  '\\u038d',\n",
              "  'Ύ',\n",
              "  'Ώ',\n",
              "  'ΐ',\n",
              "  'Α',\n",
              "  'Β',\n",
              "  'Γ',\n",
              "  'Δ',\n",
              "  'Ε',\n",
              "  'Ζ',\n",
              "  'Η',\n",
              "  'Θ',\n",
              "  'Ι',\n",
              "  'Κ',\n",
              "  'Λ',\n",
              "  'Μ',\n",
              "  'Ν',\n",
              "  'Ξ',\n",
              "  'Ο',\n",
              "  'Π',\n",
              "  'Ρ',\n",
              "  '\\u03a2',\n",
              "  'Σ',\n",
              "  'Τ',\n",
              "  'Υ',\n",
              "  'Φ',\n",
              "  'Χ',\n",
              "  'Ψ',\n",
              "  'Ω',\n",
              "  'Ϊ',\n",
              "  'Ϋ',\n",
              "  'ά',\n",
              "  'έ',\n",
              "  'ή',\n",
              "  'ί',\n",
              "  'ΰ',\n",
              "  'α',\n",
              "  'β',\n",
              "  'γ',\n",
              "  'δ',\n",
              "  'ε',\n",
              "  'ζ',\n",
              "  'η',\n",
              "  'θ',\n",
              "  'ι',\n",
              "  'κ',\n",
              "  'λ',\n",
              "  'μ',\n",
              "  'ν',\n",
              "  'ξ',\n",
              "  'ο',\n",
              "  'π',\n",
              "  'ρ',\n",
              "  'ς',\n",
              "  'σ',\n",
              "  'τ',\n",
              "  'υ',\n",
              "  'φ',\n",
              "  'χ',\n",
              "  'ψ',\n",
              "  'ω',\n",
              "  'ϊ',\n",
              "  'ϋ',\n",
              "  'ό',\n",
              "  'ύ',\n",
              "  'ώ',\n",
              "  'Ϗ',\n",
              "  'ϐ',\n",
              "  'ϑ',\n",
              "  'ϒ',\n",
              "  'ϓ',\n",
              "  'ϔ',\n",
              "  'ϕ',\n",
              "  'ϖ',\n",
              "  'ϗ',\n",
              "  'Ϙ',\n",
              "  'ϙ',\n",
              "  'Ϛ',\n",
              "  'ϛ',\n",
              "  'Ϝ',\n",
              "  'ϝ',\n",
              "  'Ϟ',\n",
              "  'ϟ',\n",
              "  'Ϡ',\n",
              "  'ϡ',\n",
              "  'Ϣ',\n",
              "  'ϣ',\n",
              "  'Ϥ',\n",
              "  'ϥ',\n",
              "  'Ϧ',\n",
              "  'ϧ',\n",
              "  'Ϩ',\n",
              "  'ϩ',\n",
              "  'Ϫ',\n",
              "  'ϫ',\n",
              "  'Ϭ',\n",
              "  'ϭ',\n",
              "  'Ϯ',\n",
              "  'ϯ',\n",
              "  'ϰ',\n",
              "  'ϱ',\n",
              "  'ϲ',\n",
              "  'ϳ',\n",
              "  'ϴ',\n",
              "  'ϵ',\n",
              "  '϶',\n",
              "  'Ϸ',\n",
              "  'ϸ',\n",
              "  'Ϲ',\n",
              "  'Ϻ',\n",
              "  'ϻ',\n",
              "  'ϼ',\n",
              "  'Ͻ',\n",
              "  'Ͼ',\n",
              "  'Ͽ',\n",
              "  'Ѐ',\n",
              "  'Ё',\n",
              "  'Ђ',\n",
              "  'Ѓ',\n",
              "  'Є',\n",
              "  'Ѕ',\n",
              "  'І',\n",
              "  'Ї',\n",
              "  'Ј',\n",
              "  'Љ',\n",
              "  'Њ',\n",
              "  'Ћ',\n",
              "  'Ќ',\n",
              "  'Ѝ',\n",
              "  ...],\n",
              " 32172)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chars = ''\n",
        "with open('vocab.txt','r',encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "    chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "chars, vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfbQ26hYpSz1",
        "outputId": "3f225e3a-de78-4c73-9b9e-a68c05fb8ce8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 8650,     1, 12531,     1,  5880,     1, 16393,     1, 14550,     1,\n",
              "          402,     1, 22748,     1, 27476,     1, 24594,     1, 30483,     1,\n",
              "         7857,     1, 25349,     1, 28399,     1, 15196,     1, 10941,     1,\n",
              "         1583,     1,  4771,     1, 18167,     1, 20621,     1, 29433,     1,\n",
              "         1873,     1,  8321,     1,  6083,     1, 11224,     1, 25820,     1,\n",
              "        12237,     1, 29977,     1, 14701,     1,  1983,     1,  1038,     1,\n",
              "        30404,     1, 10560,     1, 16042,     1, 16909,     1, 16569,     1,\n",
              "        17888,     1, 16942,     1, 14934,     1, 12518,     1, 28189,     1,\n",
              "        21013,     1,  6815,     1,  8162,     1,  4562,     1,  7485,     1,\n",
              "        10306,     1,  2715,     1, 22333,     1, 30114,     1,   288,     1])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "string_to_int = {ch:i for i,ch in enumerate(chars)}\n",
        "int_to_string = {i:ch for i,ch in enumerate(chars)}\n",
        "encode = lambda s: [string_to_int[c] for c in s]\n",
        "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
        "\n",
        "data = torch.Tensor(encode(text)).type(torch.long)\n",
        "data[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "aUafrZ41pSz1"
      },
      "outputs": [],
      "source": [
        "# memory map for using small snippets of text from a single file of any size\n",
        "def get_random_chunk(split):\n",
        "    filename = 'output_train.txt' if split == 'train' else 'output_val.txt'\n",
        "    with open(filename, 'rb') as f:\n",
        "        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:\n",
        "            # Determine the file size and a random position to start reading\n",
        "            file_size = len(mm)\n",
        "            start_pos = random.randint(0, (file_size) - block_size*batch_size)\n",
        "\n",
        "            # Seek to the random position and read the block of text\n",
        "            mm.seek(start_pos)\n",
        "            block = mm.read(block_size*batch_size-1)\n",
        "\n",
        "            # Decode the block to a string, ignoring any invalid byte sequences\n",
        "            decoded_block = block.decode('utf-8', errors='ignore').replace('\\r', '')\n",
        "\n",
        "            # Train and test splits\n",
        "            data = torch.tensor(encode(decoded_block), dtype=torch.long)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def get_batch(split):\n",
        "    data = get_random_chunk(split)\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wR2AH6ThpSz3"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input of size (batch, time-step, channels)\n",
        "        # output of size (batch, time-step, head size)\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,hs)\n",
        "        q = self.query(x) # (B,T,hs)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = nn.functional.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,hs)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
        "        return out\n",
        "\n",
        "# [1, 0, 0]\n",
        "# [1, 0.6, 0]\n",
        "# [1, 0.6, 0.4]\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1) # (B, T, F) -> (B, T, [h1, h1, h1, h1, h2, h2, h2, h2, h3, h3, h3, h3])\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.sa(x)\n",
        "        x = self.ln1(x + y)\n",
        "        y = self.ffwd(x)\n",
        "        x = self.ln2(x + y)\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, index, targets=None):\n",
        "        B, T = index.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(index) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = nn.functional.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, index, max_new_tokens):\n",
        "        # index is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            index_cond = index[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self.forward(index_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = nn.functional.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            index = torch.cat((index, index_next), dim=1) # (B, T+1)\n",
        "        return index\n",
        "\n",
        "model = GPTLanguageModel(vocab_size).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gN2kpbFNpSz4"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h17-pmTlqevk",
        "outputId": "0e8ef00c-6317-423b-8865-cff71c61e0d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Oct 15 09:49:07 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    26W /  70W |    727MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGazifWdpSz4",
        "outputId": "ac46eb71-0f3f-4a81-b2c0-68edb56cc659"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step: 0, train loss: 10.499, val loss: 10.493\n",
            "step: 100, train loss: 2.449, val loss: 2.476\n",
            "step: 200, train loss: 2.340, val loss: 2.361\n",
            "step: 300, train loss: 2.335, val loss: 2.218\n",
            "step: 400, train loss: 2.263, val loss: 2.229\n",
            "step: 500, train loss: 2.117, val loss: 2.103\n",
            "step: 600, train loss: 2.099, val loss: 2.142\n",
            "step: 700, train loss: 1.965, val loss: 2.003\n",
            "step: 800, train loss: 2.072, val loss: 2.042\n",
            "step: 900, train loss: 1.922, val loss: 1.879\n",
            "step: 1000, train loss: 1.851, val loss: 1.875\n",
            "step: 1100, train loss: 1.813, val loss: 1.916\n",
            "step: 1200, train loss: 1.784, val loss: 1.843\n",
            "step: 1300, train loss: 1.767, val loss: 1.811\n",
            "step: 1400, train loss: 1.790, val loss: 1.788\n",
            "step: 1500, train loss: 1.748, val loss: 1.741\n",
            "step: 1600, train loss: 1.763, val loss: 1.710\n",
            "step: 1700, train loss: 1.710, val loss: 1.705\n",
            "step: 1800, train loss: 1.727, val loss: 1.689\n",
            "step: 1900, train loss: 1.666, val loss: 1.643\n",
            "step: 2000, train loss: 1.719, val loss: 1.714\n",
            "step: 2100, train loss: 1.688, val loss: 1.649\n",
            "step: 2200, train loss: 1.688, val loss: 1.641\n",
            "step: 2300, train loss: 1.668, val loss: 1.746\n",
            "step: 2400, train loss: 1.603, val loss: 1.642\n",
            "step: 2500, train loss: 1.647, val loss: 1.630\n",
            "step: 2600, train loss: 1.663, val loss: 1.572\n",
            "step: 2700, train loss: 1.579, val loss: 1.526\n",
            "step: 2800, train loss: 1.609, val loss: 1.647\n",
            "step: 2900, train loss: 1.613, val loss: 1.622\n",
            "1.7837682962417603\n",
            "model saved\n"
          ]
        }
      ],
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "    if iter % eval_iters == 0:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = model.forward(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "print(loss.item())\n",
        "\n",
        "with open('gpt_model.pkl', 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "print('model saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi4gCrkJF4f3",
        "outputId": "6dd233e2-91e8-4c26-b4a6-c00d88af4ac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model parameters...\n",
            "Loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "model = GPTLanguageModel(vocab_size)\n",
        "print('Loading model parameters...')\n",
        "with open('gpt_model.pkl','rb') as f:\n",
        "  model = pickle.load(f)\n",
        "print('Loaded successfully!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eHQGvTNpSz4",
        "outputId": "dacd7e18-7aa1-4629-aaa0-aa218d446fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! Can you see me?\n",
            "\n",
            "Malty’s scept for in his not to the appearehorder the plicy of teses perfencizes or ays $136%, fun\n"
          ]
        }
      ],
      "source": [
        "prompt = 'Hello! Can you see me?'\n",
        "context = torch.tensor(encode(prompt), dtype=torch.long, device=device)\n",
        "generated_chars = decode(model.generate(context.unsqueeze(0), max_new_tokens=100)[0].tolist())\n",
        "print(generated_chars)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
